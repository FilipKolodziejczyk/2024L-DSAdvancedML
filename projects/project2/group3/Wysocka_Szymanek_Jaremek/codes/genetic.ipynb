{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "x_train_path = \"../data/x_train.txt\"\n",
    "y_train_path = \"../data/y_train.txt\"\n",
    "\n",
    "x_data = np.loadtxt(x_train_path, delimiter=\" \")\n",
    "y_data = np.loadtxt(y_train_path, delimiter=\" \")\n",
    "\n",
    "print(\"X shape:\", x_data.shape)\n",
    "print(\"Y shape:\", y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COLS = 2\n",
    "MAX_COLS = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1_000\n",
    "train_size = x_data.shape[0] - test_size\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size=test_size, shuffle=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    return GradientBoostingClassifier(n_estimators=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual(num_features):\n",
    "    num_selected_features = random.randint(MIN_COLS, MAX_COLS)\n",
    "    individual = [0] * num_features\n",
    "    selected_features = random.sample(\n",
    "        range(num_features),\n",
    "        num_selected_features\n",
    "    )\n",
    "\n",
    "    for idx in selected_features:\n",
    "        individual[idx] = 1\n",
    "    return individual\n",
    "\n",
    "\n",
    "# def mutate(individual, mutation_rate):\n",
    "#     num_features = len(individual)\n",
    "#     for i in range(num_features):\n",
    "#         if random.random() < mutation_rate:\n",
    "#             individual[i] = 1 - individual[i]\n",
    "\n",
    "#     # Upewnij się, że liczba wybranych kolumn jest w zakresie od 3 do 10\n",
    "#     num_selected_features = sum(individual)\n",
    "#     if num_selected_features < MIN_COLS:\n",
    "#         additional_features = random.sample(\n",
    "#             [i for i in range(num_features) if individual[i] == 0],\n",
    "#             MIN_COLS - num_selected_features\n",
    "#             )\n",
    "\n",
    "#         for idx in additional_features:\n",
    "#             individual[idx] = 1\n",
    "\n",
    "#     elif num_selected_features > MAX_COLS:\n",
    "#         excessive_features = random.sample(\n",
    "#             [i for i in range(num_features) if individual[i] == 1],\n",
    "#             num_selected_features - MAX_COLS\n",
    "#             )\n",
    "\n",
    "#         for idx in excessive_features:\n",
    "#             individual[idx] = 0\n",
    "\n",
    "#     return individual\n",
    "\n",
    "\n",
    "def mutate(individual, mutation_rate):\n",
    "    num_features = len(individual)\n",
    "    for i in range(num_features):\n",
    "        if random.random() < mutation_rate:\n",
    "            individual[i] = 1 - individual[i]\n",
    "\n",
    "    num_selected_features = sum(individual)\n",
    "    if num_selected_features < MIN_COLS:\n",
    "        additional_features = random.sample(\n",
    "            [i for i in range(num_features) if individual[i] == 0],\n",
    "            MIN_COLS - num_selected_features\n",
    "        )\n",
    "\n",
    "        for idx in additional_features:\n",
    "            individual[idx] = 1\n",
    "\n",
    "    elif num_selected_features > MAX_COLS:\n",
    "        excessive_features = random.sample(\n",
    "            [i for i in range(num_features) if individual[i] == 1],\n",
    "            num_selected_features - MAX_COLS\n",
    "        )\n",
    "\n",
    "        for idx in excessive_features:\n",
    "            individual[idx] = 0\n",
    "\n",
    "    return individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "def calculate_hash(individual):\n",
    "    individual_str = ''.join(map(str, individual))\n",
    "    hash_object = hashlib.sha256(individual_str.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    return hash_hex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fitted(model):\n",
    "    return hasattr(model, \"estimators_\")\n",
    "\n",
    "\n",
    "def fitness(individual, get_model_func, X_train, X_test, y_train, y_test) -> int:\n",
    "    selected_features = [\n",
    "        index\n",
    "        for index, bit in enumerate(individual)\n",
    "        if bit == 1\n",
    "        ]\n",
    "\n",
    "    if len(selected_features) == 0:\n",
    "        return -np.inf\n",
    "\n",
    "    X_train_subset = X_train[:, selected_features]\n",
    "    X_test_subset = X_test[:, selected_features]\n",
    "\n",
    "    model = get_model_func()\n",
    "    assert is_fitted(model) == False\n",
    "\n",
    "    model.fit(X_train_subset, y_train)\n",
    "    y_pred = model.predict(X_test_subset)\n",
    "\n",
    "    num_correct = np.sum((y_test == 1) & (y_pred == 1))\n",
    "    profit = num_correct * 20 - len(selected_features) * 200\n",
    "    return profit\n",
    "\n",
    "\n",
    "def select_winner(individual1, individual2, model, X_train, X_test, y_train, y_test):\n",
    "    profit1 = fitness(individual1, model, X_train, X_test, y_train, y_test);\n",
    "    profit2 = fitness(individual2, model, X_train, X_test, y_train, y_test);\n",
    "    \n",
    "    if profit1 > profit2:\n",
    "        return individual1, profit1;\n",
    "    else:\n",
    "        return individual2, profit2;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection(population, scores, k=3):\n",
    "    selected = random.sample(range(len(population)), k)\n",
    "    selected_scores = [scores[i] for i in selected]\n",
    "    return population[selected[np.argmax(selected_scores)]]\n",
    "\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    point = random.randint(1, len(parent1) - 2)\n",
    "    child1 = parent1[:point] + parent2[point:]\n",
    "    child2 = parent2[:point] + parent1[point:]\n",
    "    return child1, child2\n",
    "\n",
    "\n",
    "def genetic_algorithm(n: int, population_size: int, mutation_rate: float, get_model_func, X_train, X_test, y_train, y_test):\n",
    "    num_features = X_train.shape[1]\n",
    "    population = [\n",
    "        create_individual(num_features)\n",
    "        for _ in range(population_size)\n",
    "        ]\n",
    "\n",
    "    best_individual = None\n",
    "    best_fitness = -np.inf\n",
    "\n",
    "    for generation in range(n):\n",
    "        # Ocena przystosowania dla całej populacji\n",
    "        fitness_scores = [\n",
    "            fitness(individual, get_model_func, X_train, X_test, y_train, y_test)\n",
    "            for individual in population\n",
    "            ]\n",
    "\n",
    "        # Znalezienie najlepszego osobnika w bieżącej populacji\n",
    "        for i, score in enumerate(fitness_scores):\n",
    "            if score > best_fitness:\n",
    "                best_fitness = score\n",
    "                best_individual = population[i]\n",
    "\n",
    "        new_population = []\n",
    "        while len(new_population) < population_size:\n",
    "            parent1 = tournament_selection(population, fitness_scores)\n",
    "            parent2 = tournament_selection(population, fitness_scores)\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            new_child_1 = mutate(child1, mutation_rate)\n",
    "            new_child_2 = mutate(child2, mutation_rate)\n",
    "            new_population.extend([new_child_1, new_child_2])\n",
    "\n",
    "        assert population != new_population[:population_size]\n",
    "        population = new_population[:population_size]\n",
    "        print(f\"Generation {generation}, Best Fitness: {best_fitness}\")\n",
    "\n",
    "    return best_individual, best_fitness\n",
    "\n",
    "\n",
    "N = 50\n",
    "population_size = 50\n",
    "mutation_rate = 0.1\n",
    "\n",
    "\n",
    "best_individual, best_fitness = genetic_algorithm(N, population_size, mutation_rate, get_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "selected_features = [\n",
    "    index\n",
    "    for index, bit in enumerate(best_individual)\n",
    "    if bit == 1\n",
    "    ]\n",
    "\n",
    "print(f\"Best individual (selected features): {selected_features}\")\n",
    "print(f\"Best fitness (dollars): {best_fitness}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
