{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFE\n",
    "from utils import calculate_income_1000_customers\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = pd.read_csv('data/x_train.txt', sep=' ', header=None)\n",
    "y = pd.read_csv('data/y_train.txt', sep=' ', header=None)\n",
    "\n",
    "N_ITER = 1\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example model on all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.0\n",
      "Accuracy test: 0.625\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "print(f\"Accuracy train: {np.round(accuracy_score(y_train, y_train_pred), 4)}\")\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(f\"Accuracy test: {np.round(accuracy_score(y_test, y_test_pred), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_treshold(df,df_test, t ):\n",
    "    variance = VarianceThreshold(t)\n",
    "    return variance.fit_transform(df),variance.transform(df_test)\n",
    "\n",
    "def mean_absolute_deviance(df,df_test, t):\n",
    "    mad = np.sum(np.abs(df - np.mean(df, axis=0)), axis=0) / df.shape[0]\n",
    "    return df[:, mad > t] , df_test[:, mad > t]\n",
    "\n",
    "def correlation(df, df_test,threshold = 0.85):\n",
    "    columns_correlated = set()  \n",
    "    correlation_matrix = df.corr()\n",
    "    n = len(correlation_matrix.columns)\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "                colname = correlation_matrix.columns[i]                  \n",
    "                columns_correlated.add(colname)\n",
    "    df_new = df.drop(columns_correlated, axis=1)\n",
    "    df_test_new = df_test.drop(columns_correlated, axis=1)\n",
    "    return df_new, df_test_new\n",
    "\n",
    "def fisher_score(df,y_train, df_test, t):\n",
    "    chi2_selector = SelectKBest(chi2, k=t)\n",
    "    chi2_selector.fit(df, y_train)\n",
    "    return df.loc[:, chi2_selector.get_support()],df_test.loc[:, chi2_selector.get_support()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features:  500\n",
      "Number of features after variance treshold:  300\n",
      "Number of features after mean_absolute_deviance:  100\n",
      "Number of features after correlation:  100\n",
      "Number of features after fisher score:  5\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"variance_threshold\": 0.1,\n",
    "    \"mean_absolute_deviance\": 2,\n",
    "    \"high_correlation\": 0.8,\n",
    "    \"fisher_score\": 5,\n",
    "    \"forward_feature_selection\": 3,\n",
    "}\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "print('Original number of features: ', X_train.shape[1])\n",
    "\n",
    "X_train_new, X_test_new = variance_treshold(X_train,X_test, parameters[\"variance_threshold\"])\n",
    "\n",
    "print('Number of features after variance treshold: ', X_train_new.shape[1])\n",
    "\n",
    "X_train_new, X_test_new = mean_absolute_deviance(X_train_new,X_test_new, parameters[\"mean_absolute_deviance\"])\n",
    "\n",
    "print('Number of features after mean_absolute_deviance: ', X_train_new.shape[1])\n",
    "\n",
    "X_train_new = pd.DataFrame(X_train_new)\n",
    "X_test_new = pd.DataFrame(X_test_new)\n",
    "\n",
    "X_train_new, X_test_new = correlation(X_train_new,X_test_new, parameters[\"high_correlation\"])\n",
    "\n",
    "print('Number of features after correlation: ', X_train_new.shape[1])\n",
    "\n",
    "X_train_new, X_test_new = fisher_score(X_train_new,y_train,X_test_new, parameters[\"fisher_score\"])\n",
    "\n",
    "print('Number of features after fisher score: ', X_train_new.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_feature_selection(df, y_train, df_test,t):\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=t)\n",
    "    sfs.fit(df, y_train)\n",
    "    return df.loc[:, sfs.get_support()], df_test.loc[:, sfs.get_support()]\n",
    "\n",
    "def recursive_feature_eliminator(df, y_train, df_test, t):\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    rfe = RFE(estimator=model, n_features_to_select=t, step=1)\n",
    "    rfe.fit(df, y_train)\n",
    "    return df.loc[:, rfe.get_support()],df_test.loc[:, rfe.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features after forward feature selection:  3\n",
      "Number of features after recursive_feature_eliminator:  3\n"
     ]
    }
   ],
   "source": [
    "X_train_ffs, X_test_ffs = forward_feature_selection(X_train_new,y_train,X_test_new, 3)\n",
    "\n",
    "print('Number of features after forward feature selection: ', X_train_ffs.shape[1])\n",
    "\n",
    "X_train_rfe, X_test_rfe = recursive_feature_eliminator(X_train_new,y_train,X_test_new, 3)\n",
    "\n",
    "print('Number of features after recursive_feature_eliminator: ', X_train_rfe.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.9038\n",
      "Accuracy test: 0.527\n",
      "Accuracy for 1000 customers : (0.535, 4750.0)\n",
      "Accuracy train: 0.9132\n",
      "Accuracy test: 0.514\n",
      "Accuracy for 1000 customers : (0.46, 4000.0)\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train_ffs, y_train)\n",
    "y_train_pred = model.predict(X_train_ffs)\n",
    "\n",
    "print(f\"Accuracy train: {np.round(accuracy_score(y_train, y_train_pred), 4)}\")\n",
    "\n",
    "y_test_pred = model.predict(X_test_ffs)\n",
    "y_proba = model.predict_proba(X_test_ffs)\n",
    "print(f\"Accuracy test: {np.round(accuracy_score(y_test, y_test_pred), 4)}\")\n",
    "\n",
    "print('Accuracy for 1000 customers :', calculate_income_1000_customers(X_train_ffs.shape[1], y_proba=y_proba, y_true=y_test, y_pred=y_test_pred))\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_rfe, y_train)\n",
    "y_train_pred = model.predict(X_train_rfe)\n",
    "print(f\"Accuracy train: {np.round(accuracy_score(y_train, y_train_pred), 4)}\")\n",
    "\n",
    "y_test_pred = model.predict(X_test_rfe)\n",
    "y_proba = model.predict_proba(X_test_rfe)\n",
    "print(f\"Accuracy test: {np.round(accuracy_score(y_test, y_test_pred), 4)}\")\n",
    "\n",
    "print('Accuracy for 1000 customers :', calculate_income_1000_customers(X_train_ffs.shape[1], y_proba=y_proba, y_true=y_test, y_pred=y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
