{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "from metrics import default_competition_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"../data/x_train.npy\")\n",
    "y_train = np.load(\"../data/y_train.npy\")\n",
    "X_val = np.load(\"../data/x_val.npy\")\n",
    "y_val = np.load(\"../data/y_val.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual model with blending ensemble\n",
    "testing on features [100, 102, 105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    \"n_estimators\": 1600,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"max_features\": \"log2\",\n",
    "    \"max_depth\": 10,\n",
    "    \"bootstrap\": False,\n",
    "}\n",
    "svm_params = {\n",
    "    'kernel': 'rbf',\n",
    "    'gamma': 0.01,\n",
    "    'C': 1,\n",
    "}\n",
    "xgboost_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.01,\n",
    "    'colsample_bytree': 0.75,\n",
    "}\n",
    "features = [100, 102, 105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, features]\n",
    "X_val = X_val[:, features]\n",
    "number_of_features = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_X = X_train\n",
    "train_set_y = y_train\n",
    "val_set_X = X_val\n",
    "val_set_y = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = MDS(\n",
    "    n_components=1,\n",
    "    random_state=21,\n",
    "    n_init=6,\n",
    "    normalized_stress=False,\n",
    "    eps=0.0001,\n",
    "    max_iter=600,\n",
    ")\n",
    "# this step should be calculated in every cross-validation fold so 5 * 10 = 50 times\n",
    "# but it takes a lot of time so we will do it only once and our results will be biased\n",
    "# but in validation it is done by the book\n",
    "train_mds = mds.fit_transform(train_set_X)\n",
    "val_mds = mds.fit_transform(val_set_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_X_with_mds = np.concatenate([train_set_X, train_mds], axis=1)\n",
    "val_set_X_with_mds = np.concatenate([val_set_X, val_mds], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing on cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:  6975.0 78.39536550927825\n",
      "SVM:  7136.111111111111 30.869598292906762\n",
      "RF:  6672.222222222223 67.64330923269955\n",
      "Ensemble:  7062.5 41.247895569215274\n"
     ]
    }
   ],
   "source": [
    "seeds = [21, 22, 23, 24, 25, 5111, 23525, 34934, 343243]\n",
    "rf_results = []\n",
    "svm_results = []\n",
    "xgboost_results = []\n",
    "ensemble_results = []\n",
    "\n",
    "for num, seed in enumerate(seeds):\n",
    "    cv_folds = 5\n",
    "    np.random.seed(seed)\n",
    "    idx = np.array(range(X_train.shape[0]))\n",
    "    np.random.shuffle(idx)\n",
    "    rf = []\n",
    "    svm = []\n",
    "    xgboost = []\n",
    "    ensemble = []\n",
    "\n",
    "    idx = idx % cv_folds\n",
    "    for j in range(cv_folds):\n",
    "        X_train_cv = train_set_X_with_mds[idx != j]\n",
    "        X_val_cv = train_set_X_with_mds[idx == j]\n",
    "        X_train_cv_with_mds = train_set_X_with_mds[idx != j]\n",
    "        X_val_cv_with_mds = train_set_X_with_mds[idx == j]\n",
    "        y_train_cv = y_train[idx != j]\n",
    "        y_val_cv = y_train[idx == j]\n",
    "\n",
    "        model1 = xgb.XGBClassifier(**xgboost_params)\n",
    "        model1.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        model2 = SVC(probability=True, **svm_params)\n",
    "        model2.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        model3 = RandomForestClassifier(**rf_params)\n",
    "        model3.fit(X_train_cv_with_mds, y_train_cv)\n",
    "        \n",
    "        predictions1_train = model1.predict_proba(X_train_cv_with_mds)[:, 1]\n",
    "        predicions2_train = model2.predict_proba(X_train_cv_with_mds)[:, 1]\n",
    "        predictions3_train = model3.predict_proba(X_train_cv_with_mds)[:, 1]\n",
    "\n",
    "        predictions1 = model1.predict_proba(X_val_cv_with_mds)[:, 1]\n",
    "        predictions2 = model2.predict_proba(X_val_cv_with_mds)[:, 1]\n",
    "        predictions3 = model3.predict_proba(X_val_cv_with_mds)[:, 1]\n",
    "        \n",
    "        X_big = np.concatenate([X_train_cv_with_mds, predictions1_train.reshape(-1, 1), predictions1_train.reshape(-1, 1), predictions1_train.reshape(-1, 1)], axis=1)\n",
    "\n",
    "        ensemble_model = RandomForestClassifier(n_estimators=1000, max_depth=3, min_samples_split=2, min_samples_leaf=1, bootstrap=False)\n",
    "        \n",
    "        ensemble_model.fit(X_big, y_train_cv)\n",
    "        final_predictions_proba = ensemble_model.predict_proba(np.concatenate([X_val_cv_with_mds, predictions1.reshape(-1, 1), predictions2.reshape(-1, 1), predictions3.reshape(-1, 1)], axis=1))[:, 1]\n",
    "\n",
    "        xgboost.append(\n",
    "            default_competition_metric(\n",
    "                y_val_cv, y_pred_proba=predictions1, k=number_of_features\n",
    "            )\n",
    "        )\n",
    "        svm.append(\n",
    "            default_competition_metric(\n",
    "                y_val_cv, y_pred_proba=predictions2, k=number_of_features\n",
    "            )\n",
    "        )\n",
    "        rf.append(\n",
    "            default_competition_metric(\n",
    "                y_val_cv, y_pred_proba=predictions3, k=number_of_features\n",
    "            )\n",
    "        )\n",
    "        ensemble.append(\n",
    "            default_competition_metric(\n",
    "                y_val_cv, y_pred_proba=final_predictions_proba, k=number_of_features\n",
    "            )\n",
    "        )\n",
    "\n",
    "    xgboost_results.append(np.mean(xgboost))\n",
    "    svm_results.append(np.mean(svm))\n",
    "    rf_results.append(np.mean(rf))\n",
    "    ensemble_results.append(np.mean(ensemble))\n",
    "\n",
    "\n",
    "print(\"XGBoost: \", np.mean(xgboost_results), np.std(xgboost_results))\n",
    "print(\"SVM: \", np.mean(svm_results), np.std(svm_results))\n",
    "print(\"RF: \", np.mean(rf_results), np.std(rf_results))\n",
    "print(\"Ensemble: \", np.mean(ensemble_results), np.std(ensemble_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb score on validation set: 6650.0\n",
      "svm score on validation set: 6950.0\n",
      "rf score on validation set: 6700.0\n",
      "Ensemble score on validation set: 6650.0\n"
     ]
    }
   ],
   "source": [
    "model1 = xgb.XGBClassifier(**xgboost_params)\n",
    "model1.fit(train_set_X_with_mds, train_set_y)\n",
    "\n",
    "model2 = SVC(probability=True, **svm_params)\n",
    "model2.fit(train_set_X_with_mds, train_set_y)\n",
    "\n",
    "model3 = RandomForestClassifier(**rf_params)\n",
    "model3.fit(train_set_X_with_mds, train_set_y)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "predictions1 = model1.predict_proba(val_set_X_with_mds)[:, 1]\n",
    "predictions2 = model2.predict_proba(val_set_X_with_mds)[:, 1]\n",
    "predictions3 = model3.predict_proba(val_set_X_with_mds)[:, 1]\n",
    "\n",
    "predictions1_train = model1.predict_proba(train_set_X_with_mds)[:, 1]\n",
    "predicions2_train = model2.predict_proba(train_set_X_with_mds)[:, 1]\n",
    "predictions3_train = model3.predict_proba(train_set_X_with_mds)[:, 1]\n",
    "\n",
    "X_big = np.concatenate([train_set_X_with_mds, predictions1_train.reshape(-1, 1), predictions1_train.reshape(-1, 1), predictions1_train.reshape(-1, 1)], axis=1)\n",
    "\n",
    "ensemble_model = RandomForestClassifier(n_estimators=1000, max_depth=3, min_samples_split=2, min_samples_leaf=1, bootstrap=False)\n",
    "\n",
    "ensemble_model.fit(X_big, train_set_y)\n",
    "final_predictions_proba = ensemble_model.predict_proba(np.concatenate([val_set_X_with_mds, predictions1.reshape(-1, 1), predictions2.reshape(-1, 1), predictions3.reshape(-1, 1)], axis=1))[:, 1]\n",
    "\n",
    "\n",
    "# Combine the predictions\n",
    "final_score = default_competition_metric(\n",
    "    y_val, y_pred_proba=final_predictions_proba, k=number_of_features\n",
    ")\n",
    "print(\n",
    "    f\"xgb score on validation set: {default_competition_metric(y_val, y_pred_proba=predictions1, k=number_of_features)}\"\n",
    ")\n",
    "print(\n",
    "    f\"svm score on validation set: {default_competition_metric(y_val, y_pred_proba=predictions2, k=number_of_features)}\"\n",
    ")\n",
    "print(\n",
    "    f\"rf score on validation set: {default_competition_metric(y_val, y_pred_proba=predictions3, k=number_of_features)}\"\n",
    ")\n",
    "print(f\"Ensemble score on validation set: {final_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asseco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
